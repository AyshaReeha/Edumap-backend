Here are five things to know about neural networks in under five minutes. Number one, neural networks are composed of node layers. There is an input node layer. There is a hidden layer and there is an output layer. And these neural networks reflect the behavior of the human brain, allowing computer programs to recognize patterns and solve common problems in the fields of AI and deep learning. In fact, we should be describing this as an artificial neural network or an ANN to distinguish it from the very unartificial neural network that's operating in our heads. Now think of each node or artificial neuron as its own linear regression model. That's number two. Linear regression is a mathematical model that's used to predict future events. The weights of the connections between the nodes determines how much influence each input has on the output. So each node is composed of input data, weights, a bias or a threshold, and then an output. Now data is passed from one layer in the neural network to the next in what is known as a feed-forward network. Number three, to illustrate this, let's consider what a single node in our neural network might look like to decide should we go surfing. But decision to go or not is our predicted outcome or known as our Y hat. Let's assume there are three factors influencing our decision. The wave's good, 1 for yes or 0 for no. The waves are pumping, so x1 equals 1 on the yes. Is the line up empty? Well, unfortunately not, so let's get zero. And then let's consider is it shark free out there? That's x3. And yet no shark attacks have been reported. Now to each decision we assign a weight based on its importance on a scale of 0 to 5. So let's say that the waves, we're going to score that one. No, this is important, let's give it a 5. And for the crowds, that's w2. Not so important, we'll give that a 2. And sharks, well we'll give that a score of a 4. Now we can plug in these values into the formula to get the desired output. So Y hat equals 1 times 5 plus 0 times 2 plus 1 times 4. Then minus 3, that's our threshold. And that gives us a value of 6. 6 is greater than 0, so the output of this node is 1. We're going surfing. And if we adjust the weights of the threshold, we can achieve different outcomes. Number 4. Well, yes, but number 4. NeuroNetworks rely on training data to learn and improve the accuracy over time. We leverage supervised learning on labeled data sets to train the algorithm. As we train the model, we'll want to evaluate its accuracy using something called a cost function. Ultimately, the goal is to minimize our cost function to ensure the correctness fit for any given observation. And that happens as the model adjusts its weight and biases to fit the training data set. Through what's known as gradient descent, allowing the model to determine the direction to take to reduce errors or, more specifically, minimize the cost function. And then, finally, number 5. There are multiple types of neural networks beyond the feed forward neural network that we've described here. For example, there are convolutional neural networks known as CNNs, which have a unique architecture that's well suited for identifying patterns like image recognition. And there are recurrent neural networks, or RNNs, which are identified by their feedback loops and RNNs are primarily leveraged, using time series data to make predictions about future events like sales forecasting. So five things in five minutes. To learn more about neural networks, check out these videos. Thanks for watching.